\section{Theoretical Foundation: The Three-Layer Semantic Visibility Model}

The Generative Engine Optimization (GEO) framework is underpinned by a structured understanding of how large language models (LLMs) discover, interpret, and cite web content. Building on citation behavior observed in generative engines such as ChatGPT and Perplexity, we propose a three-layer semantic visibility model that captures the pathways through which content becomes quotable within generative responses. Each layer corresponds to a distinct mechanism in the LLM's information ingestion and synthesis pipeline, and maps directly to modifiable aspects of web content architecture.

\subsection{Layer 1: Semantic Anchoring}

Semantic Anchoring refers to the ability of content to be clearly classified and contextually grounded by the LLM during pre-retrieval and indexing phases. Empirical evidence from Aggarwal et al. \cite{aggarwal2024geo} suggests that generative engines favor sources with well-defined topical scope and explicit structural cues. To this end, content optimized for semantic anchoring must exhibit:
\begin{itemize}
  \item Descriptive and unambiguous titles
  \item Introductory summary paragraphs, typically within the first 150--300 characters
  \item Hierarchical heading structures (H1--H3)
\end{itemize}

Semantic anchoring aligns with Liu et al. \cite{liu2023verifiability}, who found that predictable structure and salient topic signals improve citation grounding and retrieval performance in LLMs.

\subsection{Layer 2: Context Triggering}

Context Triggering addresses the retrievability of content across a broad spectrum of semantically equivalent or related queries. Unlike traditional search engines that rely on keyword frequency and anchor text, LLMs rely on internal embeddings and semantic matchings. Thus, a page must include:
\begin{itemize}
  \item Synonymic and paraphrased phrasing of key ideas
  \item Domain-specific terminology and taxonomical language
  \item Multi-level complexity layering (for both lay and expert audiences)
\end{itemize}

This design enables the content to surface regardless of user literacy level or phrasing strategy, a concept supported by Aggarwal et al. \cite{aggarwal2024geo} and operationalized in their GEO-Bench multi-domain query coverage model.

\subsection{Layer 3: Pragmatic Recomposition}

The final layer, Pragmatic Recomposition, ensures that content is modular and syntactically robust enough to be extracted, rephrased, or partially quoted by an LLM while preserving its semantic integrity. This layer is critical for maximizing inclusion in generative responses. Key features include:
\begin{itemize}
  \item Modular paragraphing (3--5 sentence blocks, each centered on one idea)
  \item Q\&A structures and FAQ blocks, ideally marked with \texttt{FAQPage} schema
  \item List and step-wise formatting for procedural content
  \item Standalone factual sentences, especially for statistics or definitions
\end{itemize}

This approach is aligned with L\"uttgenau et al. \cite{luttgenau2025beyondseo}, whose fine-tuned summarization models were trained on (w, w') pairs---where w' embodied modular, citation-ready outputs.

\subsection{Layer Synergy and Diagnostic Value}

Although the three layers are analytically distinct, they are operationally interdependent. Content that is semantically anchored but not pragmatically modular may be retrieved but not cited. Conversely, highly modular content without semantic clarity may be cited out of context or not cited at all. We thus propose that effective GEO optimization requires simultaneous attention to all three layers, and should be evaluated using a multi-factor diagnostic framework as detailed in Section~\ref{sec:metrics}.
